- case 1 
    - dense 1 
    - sigmoid , no softmax  it will give 50% accuracy
    - binary cross entropy loss
    - normal labels not categorical 

- case 2 
    - dense 2
    - softmax
    - categorical cross entropy
    - categorical labels


|Epoch| Training Accuracy | Training Loss
---|----|---
1| 0.59|0.9185
2| 0.8679|0.3195
3| 0.9316|0.1129
4| 0.9638|0.0932
5| 0.98.45|0.0315
